{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "The main idea of this assignment is to understand the convolutional neural networks and the basics of image filtering. Matrix convolution and convolutional layer will be implemented from scratch. \n",
    "\n",
    "1. **Please copy the code from the previous assignment into a separate file `Blocks.py`. Put there the implementation of the building blocks.** \n",
    "\n",
    "2. All functions should be implemented in **NumPy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "* [1. Recap](#1.-Recap)\n",
    "* [2. Matrix Convolution](#2.-Matrix-Convolution)\n",
    "* [3. Basic Kernels](#3.-Basic-Kernels)\n",
    "* [4. Convolutional Layer](#4.-Convolutional-Layer)\n",
    "* [5. MaxPooling Layer](#5.-MaxPooling-Layer)\n",
    "* [6. Flatten](#6.-Flatten)\n",
    "* [7. Experiments](#7.-Experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recap\n",
    "\n",
    "During the previous assignment, you implemented the main building blocks of the neural networks: **Dense Layer**, nonlinearities, losses, and optimizers.\n",
    "* Dense layer is useful enough\n",
    "* Dense layer performs the following mapping of the input matrix $X$ (matrix of objects): \n",
    "$$\n",
    "X \\rightarrow XW + b\n",
    "$$\n",
    "* It allows one to build and train flexible models \n",
    "* Let's look precisely at image processing with Dense Layer\n",
    "    * We have a grayscale image $x$ of size $N \\times M$\n",
    "    * We reshape it into a vector of length $NM$\n",
    "    * Then we map it with a dense layer\n",
    "    * And obtain the transformed vector $y$\n",
    "    * Each element of $y$ depends on each element of $x$. That's why it is also called **Fully-Connected**\n",
    "* When we work with images, we assume that each pixel is correlated with its neighbours and close pixels. Distant pixels are not corellated. Various experiments demonstrate that this assumption is correct.\n",
    "* Dense layer captures these corellations, but it also captures *noisy* corellations. \n",
    "* There is a way to create **Locally-Connected** layer which will learn only local corellations with less number of parameters.\n",
    "* This layer is called **Convolutional Layer** and it is based on **matrix convolution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easier to understand the convolution when you see the image. Here is the image. ![](https://camo.githubusercontent.com/709b7f5eb5203b41f9456f887787b6ea790878b5/68747470733a2f2f636f6d6d756e6974792e61726d2e636f6d2f6366732d66696c652f5f5f6b65792f636f6d6d756e6974797365727665722d626c6f67732d636f6d706f6e656e74732d7765626c6f6766696c65732f30302d30302d30302d32302d36362f343738362e636f6e762e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We \"put\" the kernel on the matrix. Each element from the kernel is multiplied by the correcponding element of the source matrix. The results are summed and are written to the new matrix.\n",
    "\n",
    "* The output matrix has smaller size than the source one. It is so because of the border effects. \n",
    "* In order to obtain the matrix of the same size, zero padding could be used. \n",
    "\n",
    "* We have a matrix $X$ of size $N \\times M$ and a kernel K of size $(2p+1) \\times (2q +1 )$. \n",
    "* We also define $X_{ij} = 0$ for $i > N, i < 1$ and $j > M, j < 1$. It is called **zero padding**\n",
    "\n",
    "* Therefore the convolution of matrix with the kernel is defined as follows:\n",
    "\n",
    "$$\n",
    "Y = X \\star K \\\\\n",
    "Y_{ij} = \\sum\\limits_{\\alpha=0}^{2p} \\sum\\limits_{\\beta=0}^{2q}\n",
    "K_{\\alpha \\beta} X_{i + \\alpha - p, j+\\beta - q}\n",
    "$$\n",
    "\n",
    "* In machine learning this operation is called **convolution** and in mathematics it is **cross-corellation**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Blocks import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username already registered.\n"
     ]
    }
   ],
   "source": [
    "import automark as am\n",
    "username = 'sosnovik'\n",
    "# if yor are not registered\n",
    "am.register_id(username, ('ivan sosnovik', 'i.sosnovik@uva.nl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should implement matrix convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_matrix(matrix, kernel):\n",
    "    \"\"\"Perform the convolution of the matrix \n",
    "        with the kernel using zero padding\n",
    "    # Arguments\n",
    "        matrix: input matrix np.array of size `(N, M)`\n",
    "        kernel: kernel of the convolution \n",
    "            np.array of size `(2p + 1, 2q + 1)`\n",
    "    # Output\n",
    "        the result of the convolution\n",
    "        np.array of size `(N, M)`\n",
    "    \"\"\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "2 & 3 & 4 \\\\\n",
    "3 & 4 & 5 \\\\\n",
    "\\end{bmatrix} \\quad\n",
    "K = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 2 \\\\\n",
    "\\end{bmatrix} \\quad \n",
    "X \\star K = \n",
    "\\begin{bmatrix}\n",
    "7 & 10 & 3 \\\\\n",
    "10 & 14 & 6 \\\\\n",
    "3 & 6 & 8 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2, 3],\n",
    "    [2, 3, 4],\n",
    "    [3, 4, 5]\n",
    "])\n",
    "\n",
    "K = np.eye(3)\n",
    "K[-1, -1] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(conv_matrix(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am.test_student_function(username, conv_matrix, ['matrix', 'kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic Kernels\n",
    "\n",
    "Matrix convolution could be used to process the image: to blur it, to shift the image, to get the edges etc. Here is the very interesting [article](http://setosa.io/ev/image-kernels/). It is interactive. So you are able to get the better understanding of convolutions. Here are the examples of some kernels.\n",
    "\n",
    "* Sharpen Kernel \n",
    "$$ \n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 5 & -1 \\\\\n",
    "0 & -1 & 0 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "* Edge detection Filter\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "-1 & -1 & -1 \\\\\n",
    "-1 & 8 & -1 \\\\\n",
    "-1 & -1 & -1 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "* Box blur of size 3\n",
    "$$ \\frac{1}{9}\n",
    "\\begin{equation*}\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 1 & 1 \n",
    "\\end {bmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Let's play with convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_img = plt.imread('./images/dog.png')\n",
    "plt.imshow(rgb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert it to grayscale. RGB image is a 3 dimensional tensor. But grayscale image could be represented as a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = rgb_img.mean(axis=2)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's blur the image with [box blur](https://en.wikipedia.org/wiki/Box_blur). It is just a convolution of a matrix with the kernel of size $N \\times N$ of the following form:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N^2}\n",
    "\\begin{bmatrix}\n",
    "1 & \\dots  & 1\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "1 & \\dots  & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_blur(image, box_size):\n",
    "    \"\"\"Perform the blur of the image\n",
    "    # Arguments\n",
    "        image: input matrix - np.array of size `(N, M)`\n",
    "        box_size: the size of the blur kernel - int > 0  \n",
    "            the kernel is of size `(box_size, box_size)`\n",
    "    # Output\n",
    "        the result of the blur\n",
    "            np.array of size `(N, M)`\n",
    "    \"\"\"   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am.test_student_function(username, box_blur, ['image', 'box_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blur_dog = box_blur(img, box_size=5)\n",
    "plt.imshow(blur_dog, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the vertical and horizontal gradients. To perform it we just calculate the convolution of the image with the following kernels:\n",
    "\n",
    "$$\n",
    "K_h = \n",
    "\\begin{bmatrix}\n",
    "-1 & 0  & 1\\\\\n",
    "\\end{bmatrix} \\quad\n",
    "K_v = \n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0 \\\\\n",
    "-1\\\\\n",
    "\\end{bmatrix} \\\\\n",
    "X_h = X \\star K_h \\quad X_v = X \\star K_v\\\\\n",
    "$$\n",
    "\n",
    "And then we just calculate the amplitude of the gradient:\n",
    "\n",
    "$$\n",
    "X_\\text{grad} = \\sqrt{X_h^2 + X_v^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dog_h = conv_matrix(blur_dog, np.array([[-1, 0, 1]]))\n",
    "dog_v = conv_matrix(blur_dog, np.array([[-1, 0, 1]]).T)\n",
    "dog_grad = np.sqrt(dog_h ** 2 + dog_v ** 2)\n",
    "plt.imshow(dog_grad, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the edges we can work with. This is not the only way to get the edges. There are plenty of them:\n",
    "* [Canny edge detection](https://en.wikipedia.org/wiki/Canny_edge_detector)\n",
    "* [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator)\n",
    "* [Prewitt operator](https://en.wikipedia.org/wiki/Prewitt_operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you convolve an image with the kernel, you will obtaine the map of responses. The more correlated the patch of the image with the kernel, the higher the reposponse. Let's demonstarte it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 1, 1],\n",
    "    [0, 1, 0]\n",
    "])\n",
    "# create the image\n",
    "image = np.pad(pattern, [(12, 12), (10, 14)], mode='constant', constant_values=0)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('original image')\n",
    "plt.show()\n",
    "\n",
    "# add some noise\n",
    "image = 0.5 * image + 0.5 * np.random.random(image.shape)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('noisy image')\n",
    "plt.show()\n",
    "\n",
    "# let's find the cross \n",
    "response = conv_matrix(image, pattern)\n",
    "plt.imshow(response, cmap='gray')\n",
    "plt.title('local response')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brightest pixel is the place where the cross is. We can find the place where the image is locally close to the kernel. It allows one to find different patterns in the images such as eyes, legs, dogs, cats, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined the kernels and then just used them. But we can also learn them such by minimizing sime loss and making the processing as effective as it is possible. To do it, we have to define **Convolutional layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convolutional Layer\n",
    "\n",
    "Convolutional Layer works with images. Each image is a 3-dimensional object  $N_{\\text{channels}} \\times H \\times W$. And therefore, the collection of images is 4-dimensioonal tensor of shape $N_{\\text{objects}} \\times N_{\\text{channels}} \\times H \\times W$.\n",
    "\n",
    "For example, 32 RGB images of size $224 \\times 224$ are represented as a tensor of shape $32 \\times 3 \\times 224 \\times 224$\n",
    "\n",
    "Convolutional Layer takes the image as an input. Here the explanation of how it works:\n",
    "\n",
    "* The layer has `n_in * n_out` kernels. It is also a tensor of size `(n_in, n_out, kernel_h, kernel_w)`\n",
    "* It takes a 4-dimensional tensor of size `n_objects, n_in, H, W` as an input. \n",
    "    * It is a collection of `n_objects` images. \n",
    "    * Each of them has `n_in` channels\n",
    "    * The resolution of the images is `(H, W)`\n",
    "* For each of the images the following operation is performed:\n",
    "    * In order to get the 1st output channel, all the input are convolned with the corresponding kernels\n",
    "    * Then the results are summed. And this is the output channel\n",
    "    * Here is the code:\n",
    "    ```python\n",
    "    for i in range(n_out):\n",
    "        out_channel = 0.0\n",
    "        for j in range(n_in):\n",
    "            kernel_2d = K[i, j] # get the kernel from the collection of kernels\n",
    "            input_channel = input_image[j] # get just one channel of the input iamge\n",
    "            out_channel += conv_matrix(input_channel, kernel_2d) # convolve\n",
    "        output_image.append(out_channel) # append the calculated channel to the output          \n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "Here we implement convolutional layer for you. The implementation of backward is based on the idea that convolution could be represented as matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Layer. The implementation is based on \n",
    "        the representation of the convolution as matrix multiplication\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, n_out, filter_size):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.W = np.random.normal(size=(n_out, n_in, filter_size, filter_size))\n",
    "        self.b = np.zeros(n_out)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        n_obj, n_in, h, w = x_input.shape\n",
    "        n_out = len(self.W)\n",
    "        \n",
    "        self.output = []\n",
    "        \n",
    "        for image in x_input:\n",
    "            output_image = []\n",
    "            for i in range(n_out):\n",
    "                out_channel = 0.0\n",
    "                for j in range(n_in):\n",
    "                    out_channel += conv_matrix(image[j], self.W[i, j])\n",
    "                output_image.append(out_channel)\n",
    "            self.output.append(np.stack(output_image, 0))\n",
    "\n",
    "        self.output = np.stack(self.output, 0)\n",
    "        return self.output\n",
    "\n",
    "    \n",
    "    def backward(self, x_input, grad_output):\n",
    "\n",
    "        N, C, H, W = x_input.shape \n",
    "        F, C, HH, WW = self.W.shape\n",
    "        \n",
    "        pad = int((HH - 1) / 2)\n",
    "\n",
    "        self.grad_b = np.sum(grad_output, (0, 2, 3)) \n",
    "\n",
    "        # pad input array\n",
    "        x_padded = np.pad(x_input, ((0,0), (0,0), (pad, pad), (pad, pad)), 'constant')\n",
    "        H_padded, W_padded = x_padded.shape[2], x_padded.shape[3]\n",
    "        # naive implementation of im2col\n",
    "        x_cols = None\n",
    "        for i in range(HH, H_padded + 1):\n",
    "            for j in range(WW, W_padded+1):\n",
    "                for n in range(N):\n",
    "                    field = x_padded[n, :, i-HH:i, j-WW:j].reshape((1,-1))    \n",
    "                    if x_cols is None:\n",
    "                        x_cols = field\n",
    "                    else:\n",
    "                        x_cols = np.vstack((x_cols, field))\n",
    "                        \n",
    "        x_cols = x_cols.T\n",
    "\n",
    "        d_out = grad_output.transpose(1, 2, 3, 0) \n",
    "        dout_cols = d_out.reshape(F, -1) \n",
    "\n",
    "        dw_cols = np.dot(dout_cols, x_cols.T) \n",
    "        self.grad_W = dw_cols.reshape(F, C, HH, WW) \n",
    "\n",
    "        w_cols = self.W.reshape(F, -1) \n",
    "        dx_cols = np.dot(w_cols.T, dout_cols) \n",
    "\n",
    "        dx_padded = np.zeros((N, C, H_padded, W_padded))\n",
    "        idx = 0\n",
    "        for i in range(HH, H_padded + 1):\n",
    "            for j in range(WW, W_padded + 1):\n",
    "                for n in range(N):\n",
    "                    dx_padded[n:n+1, :, i-HH:i, j-WW:j] += dx_cols[:, idx].reshape((1, C, HH, WW))\n",
    "                    idx += 1\n",
    "            dx = dx_padded[:, :, pad:-pad, pad:-pad]\n",
    "        grad_input = dx\n",
    "        return grad_input\n",
    "    \n",
    "    def get_params(self):\n",
    "        return [self.W, self.b]\n",
    "\n",
    "    def get_params_gradients(self):\n",
    "        return [self.grad_W, self.grad_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this layer transorms images with 3 channels \n",
    "# into images with 8 channels \n",
    "# by convolving them with kernels of size 3x3\n",
    "conv_layer = ConvLayer(3, 8, filter_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Pooling Layer\n",
    "Pooling layer perfroms the pooling operations. The pooling layer **reduces the size of image**. There are several types of pooling operations in theory but the most commonly used one is the **max pooling**. \n",
    "\n",
    "In the following figure $2 \\times 2$ pooling is applied on the image which reduced the size of image to half. It can be observed from the figure that the pooling operation does not effect the depth of the image.\n",
    "<img src=\"./src/pool.png\" width=\"800\">\n",
    "<img src=\"./src/maxpool.png\" width=\"800\">\n",
    "\n",
    "During max pooling operation, the image is splitted into windows of size $2 \\times 2$ and then just the maximum element is chosen from each window. \n",
    "You can use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool_forward(x_input):\n",
    "    \"\"\"Perform max pooling operation with 2x2 window\n",
    "    # Arguments\n",
    "        x_input: np.array of size (2 * W, 2 * H)\n",
    "    # Output\n",
    "        output: np.array of size (W, H)\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    ################# \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am.test_student_function(username, maxpool_forward, ['x_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function is implemented for you\n",
    "# The implementation is not complicated, \n",
    "# so read it to understand the concept\n",
    "\n",
    "def maxpool_grad_input(x_input, grad_output):\n",
    "    \"\"\"Calculate partial derivative of the loss with respect to the input\n",
    "    # Arguments\n",
    "        x_input: np.array of size (2 * W, 2 * H)\n",
    "        grad_output: partial derivative of the loss \n",
    "            with respect to the output \n",
    "            np.array of size (W, H)\n",
    "    # Output\n",
    "        output: partial derivative of the loss \n",
    "            with respect to the input\n",
    "            np.array of size (2 * W, 2 * H) \n",
    "    \"\"\"\n",
    "    height, width = x_input.shape\n",
    "    # create the array of zeros of the required size\n",
    "    grad_input = np.zeros(x_input.shape)\n",
    "    \n",
    "    # let's put 1 if the element with this position \n",
    "    # is maximal in the window\n",
    "    for i in range(0, height, 2):\n",
    "        for j in range(0, width, 2):\n",
    "            window = x_input[i:i+2, j:j+2]\n",
    "            i_max, j_max = np.unravel_index(np.argmax(window), (2, 2))\n",
    "            grad_input[i + i_max, j + j_max] = 1\n",
    "            \n",
    "    # put corresponding gradient instead of 1       \n",
    "    grad_input = grad_input.ravel()\n",
    "    grad_input[grad_input == 1] = grad_output.ravel()\n",
    "    grad_input = grad_input.reshape(x_input.shape)\n",
    "    return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MaxPool2x2(Layer):\n",
    "    \n",
    "    def forward(self, x_input):\n",
    "        n_obj, n_ch, h, w = x_input.shape\n",
    "        self.output = np.zeros((n_obj, n_ch, h // 2, w // 2))\n",
    "        for i in range(n_obj):\n",
    "            for j in range(n_ch):\n",
    "                self.output[i, j] = maxpool_forward(x_input[i, j])\n",
    "        return self.output \n",
    "    \n",
    "    def backward(self, x_input, grad_output):\n",
    "        n_obj, n_ch, _, _ = x_input.shape\n",
    "        grad_input = np.zeros_like(x_input)\n",
    "        for i in range(n_obj):\n",
    "            for j in range(n_ch):\n",
    "                grad_input[i, j] = maxpool_grad_input(x_input[i, j], grad_output[i, j])\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Flatten\n",
    "Convolutional neural networks allow one to perform better image processing than fully connected neural networks. We will combine convolutional layers, wich deal with 4-dimensional tensors, with dense layers, wich work with matrices. To make it work, we should implement **Flatten** layer. \n",
    "\n",
    "Flatten layer takes a 4-dimensional tensor of size `(n_obj, n_channels, h, w)` as an input and reshaes it to a 2-dimensional tensor (matrix) of size `(n_obj, n_channels * h * w)`.\n",
    "The backward pass of this layer is not complicated. Think about it. \n",
    "\n",
    "**Please implement `flatten_forward` and `flatten_grad_input` functions using `np.reshape`**. Here is the [description](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.reshape.html) of `np.reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_forward(x_input):\n",
    "    \"\"\"Perform the reshaping of the tensor of size `(K, L, M, N)` \n",
    "        to the tensor of size `(K, L*M*N)`\n",
    "    # Arguments\n",
    "        x_input: np.array of size `(K, L, M, N)`\n",
    "    # Output\n",
    "        output: np.array of size `(K, L*M*N)`\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    #################\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am.test_student_function(username, flatten_forward, ['x_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_grad_input(x_input, grad_output):\n",
    "    \"\"\"Calculate partial derivative of the loss with respect to the input\n",
    "    # Arguments\n",
    "        x_input: partial derivative of the loss \n",
    "            with respect to the output\n",
    "            np.array of size `(K, L*M*N)`\n",
    "    # Output\n",
    "        output: partial derivative of the loss \n",
    "            with respect to the input\n",
    "            np.array of size `(K, L, M, N)`\n",
    "    \"\"\"\n",
    "    #################\n",
    "    ### YOUR CODE ###\n",
    "    #################\n",
    "    return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "am.test_student_function(username, flatten_grad_input, ['x_input', 'grad_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FlattenLayer(Layer):\n",
    "    \n",
    "    def forward(self, x_input):\n",
    "        self.output = flatten_forward(x_input)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, x_input, grad_output):\n",
    "        output = flatten_grad_input(x_input, grad_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Experiments\n",
    "\n",
    "Now we will conduct several experiments. We will train our neural networks with **minibatches**. So we split our dataset intro small portions. And feed these portions one-by-one to our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def iterate_minibatches(x, y, batch_size=16, verbose=True):\n",
    "    assert len(x) == len(y)\n",
    "    \n",
    "    indices = np.arange(len(x))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for i, start_idx in enumerate(range(0, len(x) - batch_size + 1, batch_size)):\n",
    "        if verbose:\n",
    "            print('\\rBatch: {}/{}'.format(i + 1, len(x) // batch_size), end='')\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        excerpt = indices[start_idx:start_idx + batch_size]\n",
    "        yield x[excerpt], y[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's import the data. [Download](http://yann.lecun.com/exdb/mnist/) it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset_utils import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = list(load_mnist())\n",
    "train_images = np.array([im[1] for im in train])\n",
    "train_targets = np.array([im[0] for im in train])\n",
    "# we will train 0 vs 1 classifier\n",
    "x_train = train_images[train_targets < 2][:1000]\n",
    "y_train = train_targets[train_targets < 2][:1000]\n",
    "\n",
    "y_train = y_train * 2 - 1\n",
    "y_train = y_train.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train simple convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn():\n",
    "    nn = SequentialNN()\n",
    "\n",
    "    nn.add(ConvLayer(1, 2, filter_size=3)) # The output is of size N_obj 2 28 28\n",
    "    nn.add(ReLU()) # The output is of size N_obj 2 28 28\n",
    "    nn.add(MaxPool2x2()) # The output is of size N_obj 2 14 14\n",
    "\n",
    "    nn.add(ConvLayer(2, 4, filter_size=3)) # The output is of size N_obj 4 14 14\n",
    "    nn.add(ReLU()) # The output is of size N_obj 4 14 14\n",
    "    nn.add(MaxPool2x2()) # The output is of size N_obj 4 7 7\n",
    "\n",
    "    nn.add(FlattenLayer()) # The output is of size N_obj 196\n",
    "    nn.add(Dense(4 * 7 * 7, 32))\n",
    "    nn.add(ReLU())\n",
    "    nn.add(Dense(32, 1))\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = get_cnn()\n",
    "loss = Hinge()\n",
    "optimizer = SGD(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It will train for about 5 minutes\n",
    "num_epochs = 5 \n",
    "batch_size = 32\n",
    "# we will store the results here\n",
    "history = {'loss': [], 'accuracy': []}\n",
    "\n",
    "# we will make `num_epochs` iterations\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "    \n",
    "    # we perform iteration by small batches one-by-one\n",
    "    for x_batch, y_batch in iterate_minibatches(x_train, y_train, batch_size):\n",
    "        # predict the target value\n",
    "        y_pred = nn.forward(x_batch)\n",
    "        # compute the gradient of the loss\n",
    "        loss_grad = loss.backward(y_pred, y_batch)\n",
    "        # perform backprop\n",
    "        nn.backward(x_batch, loss_grad)\n",
    "        # update the params\n",
    "        optimizer.update_params()\n",
    "        \n",
    "        # save loss and accuracy value\n",
    "        history['loss'].append(loss.forward(y_pred, y_batch))\n",
    "        prediction_is_correct = (y_pred > 0) == (y_batch > 0)\n",
    "        history['accuracy'].append(np.mean(prediction_is_correct))\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's plot the results\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "ax_1 = plt.subplot()\n",
    "ax_1.plot(history['loss'], c='g', lw=2, label='train loss')\n",
    "ax_1.set_ylabel('loss', fontsize=16)\n",
    "ax_1.set_xlabel('#batches', fontsize=16)\n",
    "\n",
    "ax_2 = plt.twinx(ax_1)\n",
    "ax_2.plot(history['accuracy'], lw=3, label='train accuracy')\n",
    "ax_2.set_ylabel('accuracy', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model with different `batch_size`\n",
    "* What would be if `batch_size=1`?\n",
    "* What would be if `batch_size=1000`?\n",
    "* Does the speed of the computations depend on this parameter? Why?\n",
    "\n",
    "* Train the model with different `num_epochs`\n",
    "* What would be if `num_epochs=1`?\n",
    "* What would be if `num_epochs=1000`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the activations of the intermediate layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_images = x_batch[:2]\n",
    "_ = nn.forward(viz_images)\n",
    "\n",
    "activations = {\n",
    "    'conv_1': nn.layers[0].output,\n",
    "    'relu_1': nn.layers[1].output,\n",
    "    'pool_1': nn.layers[2].output,\n",
    "    'conv_2': nn.layers[3].output,\n",
    "    'relu_2': nn.layers[4].output,\n",
    "    'pool_2': nn.layers[5].output,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(4, 8))\n",
    "\n",
    "ax1.imshow(viz_images[0, 0], cmap=plt.cm.gray_r)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "ax2.imshow(viz_images[1, 0], cmap=plt.cm.gray_r)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of Conv 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conv 1\n",
    "f, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['conv_1'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of ReLU 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ReLU 1\n",
    "f, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['relu_1'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of MaxPooling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Max Pooling 1\n",
    "f, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['pool_1'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of Conv 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conv 2\n",
    "f, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['conv_2'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of ReLU 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ReLU 2\n",
    "f, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['relu_2'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations of MaxPooling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Max Pooling 2\n",
    "f, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(activations['pool_2'][i, j], cmap=plt.cm.gray_r)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Channel {}'.format(j + 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we go deeper and deeper, images become less locally-corellated (the dependance between two neighbours decreases) and more semantically loaded. Each pixel now stores more information about the object. Very useful information. Which then will be analyzed with several Dense Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the architecture of the neural network\n",
    "* Vary the number of filters\n",
    "* Vary the size of the kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
